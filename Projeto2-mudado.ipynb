{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Bruno Meneghesso da Silva\n",
    "\n",
    "Nome: Diogo Nobre de Araujo Cintra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador automático de sentimento para o Twitter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install tweepy\n",
    "%matplotlib inline\n",
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import arange\n",
    "from numpy import percentile\n",
    "import numpy as np\n",
    "import os\n",
    "import re \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***@Ciencia dos dados***"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "#Configurando a biblioteca\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "#Produto escolhido:\n",
    "produto = 'Correios'\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "n = 500\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 300\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    "    msgs.append(msg.full_text.lower())\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um possível viés\n",
    "shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "#### 0 = irrelevante\n",
    "#### 1 = relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TREINAMENTO = pd.read_excel('Correios.xlsx',sheet_name = 'Treinamento')\n",
    "TESTE = pd.read_excel('Correios.xlsx',sheet_name = 'Teste')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TREINAMENTO_RELEVANTE = TREINAMENTO.loc[TREINAMENTO[\"Classificacao\"]==1]\n",
    "TREINAMENTO_IRRELEVANTE = TREINAMENTO.loc[TREINAMENTO[\"Classificacao\"]==0]\n",
    "\n",
    "def clean(text):\n",
    "    punctuation = '[!\\-.:?;#$%&*_1234567890\"]'\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_relevante = \" \".join(TREINAMENTO_RELEVANTE['Treinamento'])\n",
    "texto_relevante_1 = clean(texto_relevante)\n",
    "texto_relevante_2 = texto_relevante_1.split()\n",
    "texto_relevante_3 = []\n",
    "\n",
    "texto_irrelevante = \" \".join(TREINAMENTO_IRRELEVANTE['Treinamento'])\n",
    "texto_irrelevante_1 = clean(texto_irrelevante)\n",
    "texto_irrelevante_2 = texto_irrelevante_1.split()\n",
    "texto_irrelevante_3 = []\n",
    "\n",
    "treinamento = \" \".join(TREINAMENTO['Treinamento'])\n",
    "treinamento_1 = clean(treinamento)\n",
    "treinamento_2 = treinamento_1.split()\n",
    "treinamento_3 = []\n",
    "\n",
    "teste = \" \".join(TESTE['Teste'])\n",
    "teste_1 = clean(teste)\n",
    "teste_2 = teste_1.split()\n",
    "teste_3 = []\n",
    "\n",
    "for e in range(len(texto_relevante_2)-1):\n",
    "    if texto_relevante_2[e] != 'rt' and texto_relevante_2[e][0] != '@':     \n",
    "        texto_relevante_3.append(texto_relevante_2[e])    \n",
    "        \n",
    "for e in range(len(texto_irrelevante_2)-1):\n",
    "    if texto_irrelevante_2[e] != 'rt' and texto_irrelevante_2[e][0] != '@':     \n",
    "        texto_irrelevante_3.append(texto_irrelevante_2[e]) \n",
    "        \n",
    "for e in range(len(treinamento_2)-1):\n",
    "    if treinamento_2[e] != 'rt' and treinamento_2[e][0] != '@':     \n",
    "        treinamento_3.append(treinamento_2[e])\n",
    "        \n",
    "for e in range(len(teste_2)-1):\n",
    "    if teste_2[e] != 'rt' and teste_2[e][0] != '@':     \n",
    "        teste_3.append(teste_2[e])        \n",
    "        \n",
    "texto_relevante_4 = pd.Series(texto_relevante_3)\n",
    "texto_irrelevante_4 = pd.Series(texto_irrelevante_3)\n",
    "treinamento_4 = pd.Series(treinamento_3)\n",
    "teste_4 = pd.Series(teste_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probabilidade do tweet ser relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4013377926421405"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_relevante = len(TREINAMENTO.loc[TREINAMENTO[\"Classificacao\"]==1])/len(TREINAMENTO[\"Treinamento\"])\n",
    "prob_relevante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probabilidade do tweet ser relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5986622073578596"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_irrelevante = len(TREINAMENTO.loc[TREINAMENTO[\"Classificacao\"]==0])/len(TREINAMENTO[\"Treinamento\"])\n",
    "prob_irrelevante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6337"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_amostral_teste = len(teste_4)\n",
    "total_amostral_treinamento = len(treinamento_4)\n",
    "total_relevante = texto_relevante_4.value_counts()\n",
    "total_irrelevante = texto_irrelevante_4.value_counts()\n",
    "\n",
    "#Probabilidade da palavra ser relevante\n",
    "prob_relevante_palavra = total_relevante/total_amostral_treinamento\n",
    "prob_relevante_palavra\n",
    "\n",
    "#Probabilidade da palavra ser irrelevante\n",
    "prob_irrelevante_palavra = total_irrelevante/total_amostral_treinamento\n",
    "prob_irrelevante_palavra\n",
    "total_amostral_treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_relevante_teste = len(TESTE.loc[TESTE[\"Classificacao\"]==1])/len(TESTE[\"Teste\"])\n",
    "prob_irrelevante_teste = len(TESTE.loc[TESTE[\"Classificacao\"]==0])/len(TESTE[\"Teste\"])\n",
    "\n",
    "smoth = 1e-10 #é uma estimativa e deve mudar\n",
    "vocabulario = 356000\n",
    "\n",
    "# defini probabilidade de ser relevante:\n",
    "def relevante(tweet):\n",
    "    \n",
    "    tweet_relevante_2 = clean(tweet)\n",
    "    tweet_relevante_3 = tweet_relevante_2.split()\n",
    "    tweet_relevante_4 = []\n",
    "    \n",
    "    for e in range(len(tweet_relevante_3)-1):\n",
    "        \n",
    "        if tweet_relevante_3[e] != 'rt' and tweet_relevante_3[e][0] != '@':     \n",
    "            tweet_relevante_4.append(tweet_relevante_3[e])\n",
    "            \n",
    "    prob = 1\n",
    "    \n",
    "    for p in tweet_relevante_4:\n",
    "        \n",
    "        if p in prob_relevante_palavra:\n",
    "            prob = prob*(prob_relevante_palavra[p]*total_relevante.size+smoth)/(total_relevante.size+smoth*vocabulario)*1000\n",
    "        else:\n",
    "            prob = prob*(smoth)/(total_relevante.size+smoth*vocabulario)*1000\n",
    "            \n",
    "    prob = prob * prob_relevante\n",
    "    prob = math.log10(prob)\n",
    "    #print(prob)\n",
    "    return prob\n",
    "\n",
    "# defini probabilidade de ser irrelevante:\n",
    "def irrelevante(tweet):\n",
    "    \n",
    "    tweet_irrelevante_2 = clean(tweet)\n",
    "    tweet_irrelevante_3 = tweet_irrelevante_2.split()\n",
    "    tweet_irrelevante_4 = []\n",
    "    \n",
    "    for e in range(len(tweet_irrelevante_3)-1):\n",
    "        \n",
    "        if tweet_irrelevante_3[e] != 'rt' and tweet_irrelevante_3[e][0] != '@':     \n",
    "            tweet_irrelevante_4.append(tweet_irrelevante_3[e])\n",
    "            \n",
    "    prob = 1\n",
    "    \n",
    "    for p in tweet_irrelevante_4:\n",
    "        \n",
    "        if p in prob_irrelevante_palavra:\n",
    "            prob = prob*(prob_irrelevante_palavra[p]*total_irrelevante.size+smoth)/(total_irrelevante.size+smoth*vocabulario)*1000\n",
    "        else:\n",
    "            prob = prob*(smoth)/(total_irrelevante.size+smoth*vocabulario)*1000\n",
    "            \n",
    "    prob = prob * prob_irrelevante\n",
    "    prob = math.log10(prob)\n",
    "    #print(prob)\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compara (tweet):\n",
    "    \n",
    "    r = relevante(tweet)\n",
    "    nor = irrelevante(tweet)\n",
    "    \n",
    "    return r>nor\n",
    "\n",
    "rev = 0\n",
    "norev = 0\n",
    "\n",
    "for e in TESTE[\"Teste\"]:\n",
    "    \n",
    "    if compara(e):\n",
    "        rev +=1\n",
    "    else:\n",
    "        norev+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidade de ser relevante segundo o algoritmo: 28.499999999999996%\n",
      "Probabilidade de ser irrelevante segundo o algoritmo: 71.5%\n",
      "Probabilidade de ser relevante pela nossa classificação: 44.50%\n",
      "Probabilidade de ser irrelevante pela nossa classificação: 55.50%\n",
      "Acurácia do algoritmo: 64.04%\n"
     ]
    }
   ],
   "source": [
    "print(\"Probabilidade de ser relevante segundo o algoritmo: {}%\".format((rev/TESTE[\"Teste\"].size)*100))\n",
    "print(\"Probabilidade de ser irrelevante segundo o algoritmo: {}%\".format((norev/TESTE[\"Teste\"].size)*100))\n",
    "\"\"\"\n",
    "if rev/(TESTE[\"Teste\"].size) < 0.9*prob_relevante_teste:\n",
    "    print (\"poucos relevantes {} vezes o esperado\".format(rev/TESTE[\"Teste\"].size/prob_relevante_teste))\n",
    "    \n",
    "elif rev/(TESTE[\"Teste\"].size) > 1.1*prob_relevante_teste:\n",
    "    print (\"muitos relevantes {} vezes o esperado\" .format(rev/TESTE[\"Teste\"].size/prob_relevante_teste))\n",
    "    \n",
    "else:\n",
    "    print (\"ok: {} veze o esperado\".format (rev/TESTE[\"Teste\"].size/prob_relevante_teste))  \n",
    "\"\"\"   \n",
    "print(\"Probabilidade de ser relevante pela nossa classificação: {:.2f}%\".format(prob_relevante_teste*100))\n",
    "print(\"Probabilidade de ser irrelevante pela nossa classificação: {:.2f}%\".format(prob_irrelevante_teste*100))\n",
    "print(\"Acurácia do algoritmo: {:.2f}%\".format((rev/TESTE[\"Teste\"].size/prob_relevante_teste)*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validação da acurácia "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do resultado segundo a biblioteca: 0.65%\n"
     ]
    }
   ],
   "source": [
    "Xt = TREINAMENTO['Treinamento']\n",
    "y = TREINAMENTO['Classificacao']\n",
    "\n",
    "cnt = CountVectorizer()\n",
    "X = cnt.fit_transform(Xt)\n",
    "nb = MultinomialNB(alpha=1e-10)\n",
    "nb.fit(X, y)\n",
    "\n",
    "Xt_test = TESTE['Teste']\n",
    "y_test = TESTE['Classificacao']\n",
    "\n",
    "X_test = cnt.transform(Xt_test)\n",
    "ypred = nb.predict(X_test)\n",
    "\n",
    "acuracia_biblioteca = accuracy_score(y_test, ypred)\n",
    "\n",
    "print(\"Acurácia do resultado segundo a biblioteca: {:.2f}%\".format(acuracia_biblioteca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
